{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (102, 13)\n",
      "(404,) (102,)\n"
     ]
    }
   ],
   "source": [
    "print (train_data.shape, test_data.shape)\n",
    "print (train_targets.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train 데이터는 404개 test 데이터는 102개\n",
    "- 1개 데이터는 13 feature가 있고 보스턴 집값관련 특성이다.\n",
    "1. Per capita crime rate.\n",
    "2. Proportion of residential land zoned for lots over 25,000 square feet.\n",
    "3. Proportion of non-retail business acres per town.\n",
    "4. Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "5. Nitric oxides concentration (parts per 10 million).\n",
    "6. Average number of rooms per dwelling.\n",
    "7. Proportion of owner-occupied units built prior to 1940.\n",
    "8. Weighted distances to five Boston employment centres.\n",
    "9. Index of accessibility to radial highways.\n",
    "10. Full-value property-tax rate per $10,000.\n",
    "11. Pupil-teacher ratio by town.\n",
    "12. 1000 * (Bk - 0.63) ** 2 where Bk is the proportion of Black people by town.\n",
    "13. % lower status of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   82.5   2.    0.    0.4   7.6  15.7   6.3   2.  348.   14.7 395.4\n",
      "   3.1] 42.3\n"
     ]
    }
   ],
   "source": [
    "print(np.round(train_data[1], 1), np.round(train_targets[1], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanStdScaler(train_data, test_data):\n",
    "    mean = train_data.mean(axis=0)\n",
    "    train_data -= mean\n",
    "    std = train_data.std(axis=0)\n",
    "    train_data /= std\n",
    "\n",
    "    test_data -= mean\n",
    "    test_data /= std\n",
    "\n",
    "    # print(mean, std)\n",
    "    train_data.shape[1]\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "          0.44807713,  0.8252202 ],\n",
       "        [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "          0.43190599, -1.32920239],\n",
       "        [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "          0.22061726, -1.30850006],\n",
       "        ...,\n",
       "        [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "          0.07943894, -0.67776904],\n",
       "        [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "         -0.98764362,  0.42083466],\n",
       "        [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "          0.23317118, -1.15392266]]),\n",
       " array([[ 1.55369355, -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         -3.48459553,  2.25092074],\n",
       "        [-0.39242675, -0.48361547, -0.16087773, ..., -0.30759583,\n",
       "          0.42733126,  0.47880119],\n",
       "        [-0.39982927, -0.48361547, -0.86940196, ...,  0.78447637,\n",
       "          0.44807713, -0.41415936],\n",
       "        ...,\n",
       "        [-0.20709507, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "          0.37051949, -1.49344089],\n",
       "        [-0.36698601, -0.48361547, -0.72093526, ..., -0.48960787,\n",
       "          0.39275481, -0.41829982],\n",
       "        [-0.0889679 , -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "         -1.21946544, -0.40449827]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MeanStdScaler(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    #model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regression일 때 마지막 레이어에 Softmax라던지 sigmoid 등의 activation function이 없다.\n",
    "- Classification일 때는 분류를 해야 하므로 softmax 또는 Sigmoid 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-flod validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리중인 폴드는 # 0\n",
      "shape (101, 13) (101,)\n",
      "shape (303, 13) (303,)\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 0s 1ms/step - loss: 516.0872 - mae: 21.0339\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 297us/step - loss: 360.0110 - mae: 17.2663\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 204.7479 - mae: 12.3415\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 93.0092 - mae: 7.5129\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 45.7140 - mae: 5.0175\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 33.0973 - mae: 4.1117\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 27.4470 - mae: 3.6946\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 0s 287us/step - loss: 24.3793 - mae: 3.4330\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 21.8486 - mae: 3.2596\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 19.7309 - mae: 3.0740\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 291us/step - loss: 18.5011 - mae: 3.0130\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 17.2154 - mae: 2.8972\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 15.9541 - mae: 2.8171\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 15.3659 - mae: 2.7436\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 280us/step - loss: 14.5912 - mae: 2.6462\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 13.7951 - mae: 2.5791\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 0s 288us/step - loss: 13.3236 - mae: 2.5355\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 0s 291us/step - loss: 12.8315 - mae: 2.4752\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 12.4497 - mae: 2.4298\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 12.1478 - mae: 2.4213\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 0s 282us/step - loss: 11.6778 - mae: 2.3437\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 0s 283us/step - loss: 11.5597 - mae: 2.3680\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 11.0402 - mae: 2.3295\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 11.0073 - mae: 2.3098\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 0s 288us/step - loss: 10.5936 - mae: 2.2503\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 10.4847 - mae: 2.2057\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 0s 273us/step - loss: 10.3609 - mae: 2.2119\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 10.2296 - mae: 2.1923\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 9.8844 - mae: 2.1616\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 0s 288us/step - loss: 9.7883 - mae: 2.1790\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 9.8661 - mae: 2.1729\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 0s 294us/step - loss: 9.4411 - mae: 2.1239\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 0s 282us/step - loss: 9.6157 - mae: 2.0964\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 0s 282us/step - loss: 9.4537 - mae: 2.1276\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 9.2291 - mae: 2.1051\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 0s 273us/step - loss: 9.1444 - mae: 2.0890\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 9.1708 - mae: 2.0279\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 0s 219us/step - loss: 9.0204 - mae: 2.0484\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 0s 259us/step - loss: 8.8651 - mae: 2.0645\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 0s 299us/step - loss: 8.8806 - mae: 2.0236\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 8.7896 - mae: 2.0256\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 8.5853 - mae: 2.0444\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 8.3114 - mae: 1.9506\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 8.2471 - mae: 1.9856\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 8.3206 - mae: 1.9778\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 0s 288us/step - loss: 8.2698 - mae: 2.0080\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 8.2478 - mae: 1.9448\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 0s 287us/step - loss: 8.1521 - mae: 1.9428\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 8.2126 - mae: 1.9643\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 8.1642 - mae: 1.9387\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 7.9822 - mae: 1.9339\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 7.6879 - mae: 1.9304\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 7.9764 - mae: 1.9609\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 7.8350 - mae: 1.9517\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 7.6026 - mae: 1.8994\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 7.6398 - mae: 1.9327\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 7.5276 - mae: 1.8764\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 7.4752 - mae: 1.8526\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 7.6893 - mae: 1.8972\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 7.3017 - mae: 1.8657\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 7.2954 - mae: 1.8321\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - ETA: 0s - loss: 7.9753 - mae: 1.818 - 0s 217us/step - loss: 7.2419 - mae: 1.8333\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 7.3252 - mae: 1.8396\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 7.2295 - mae: 1.8337\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 7.4953 - mae: 1.8704\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 7.1183 - mae: 1.8121\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 0s 223us/step - loss: 7.1544 - mae: 1.8209\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 6.9327 - mae: 1.7928\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 0s 283us/step - loss: 7.1331 - mae: 1.8058\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 0s 246us/step - loss: 6.9415 - mae: 1.8165\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 6.8739 - mae: 1.7931\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 7.0151 - mae: 1.8173\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 6.7747 - mae: 1.8070\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 6.8238 - mae: 1.7305\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 6.7270 - mae: 1.7649\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 277us/step - loss: 6.6600 - mae: 1.7852\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 6.4582 - mae: 1.7734\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.7667 - mae: 1.8150\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 0s 221us/step - loss: 6.4237 - mae: 1.7464\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.7004 - mae: 1.7877\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 6.5232 - mae: 1.7508\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 0s 259us/step - loss: 6.5720 - mae: 1.7795\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 6.5126 - mae: 1.7293\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 0s 250us/step - loss: 6.2952 - mae: 1.7279\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 6.4385 - mae: 1.7241\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 6.3098 - mae: 1.7310\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 6.3113 - mae: 1.6882\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 6.1626 - mae: 1.6906\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 6.1486 - mae: 1.7212\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 6.1588 - mae: 1.7149\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 6.1499 - mae: 1.7238\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 6.1256 - mae: 1.6766\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 6.2268 - mae: 1.6569\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 5.9228 - mae: 1.6599\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 6.0337 - mae: 1.6659\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 0s 232us/step - loss: 5.8954 - mae: 1.6320\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 0s 287us/step - loss: 6.0318 - mae: 1.6643\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 0s 317us/step - loss: 5.5998 - mae: 1.6436\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 5.9438 - mae: 1.6637\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 5.8086 - mae: 1.6395\n",
      "처리중인 폴드는 # 1\n",
      "shape (101, 13) (101,)\n",
      "shape (303, 13) (303,)\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 0s 591us/step - loss: 501.8844 - mae: 20.3805\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 352.6312 - mae: 16.5193\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 192.8704 - mae: 11.4335\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 282us/step - loss: 90.3362 - mae: 7.1766\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 56.4900 - mae: 5.3951\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 40.4742 - mae: 4.4299\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 0s 282us/step - loss: 31.5833 - mae: 3.8123\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 26.5655 - mae: 3.4700\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 0s 297us/step - loss: 23.1656 - mae: 3.3114\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 0s 273us/step - loss: 20.9891 - mae: 3.0526\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 280us/step - loss: 19.2284 - mae: 3.0774\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 18.3934 - mae: 2.9015\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 17.3876 - mae: 2.8014\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 16.1751 - mae: 2.7222\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 15.1855 - mae: 2.6403\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 14.3975 - mae: 2.6652\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 14.0079 - mae: 2.5452\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 13.4809 - mae: 2.4694\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 12.8902 - mae: 2.4848\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 12.4130 - mae: 2.4424\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 0s 293us/step - loss: 12.1492 - mae: 2.3542\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 11.7793 - mae: 2.3528\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 11.2297 - mae: 2.3035\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 0s 282us/step - loss: 10.9754 - mae: 2.2880\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 10.6212 - mae: 2.2465\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 0s 300us/step - loss: 10.4836 - mae: 2.2643\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 0s 260us/step - loss: 10.1478 - mae: 2.2040\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 10.3254 - mae: 2.1942\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 0s 314us/step - loss: 10.0264 - mae: 2.1601\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 10.0121 - mae: 2.1412\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 9.6709 - mae: 2.1275\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 0s 215us/step - loss: 9.6553 - mae: 2.1349\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 9.4042 - mae: 2.1110\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 0s 295us/step - loss: 9.4390 - mae: 2.0709\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 9.2371 - mae: 2.0894\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 9.1843 - mae: 2.0714\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 8.7849 - mae: 2.0535\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 8.9972 - mae: 2.0752\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 8.8724 - mae: 2.0365\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 8.8890 - mae: 2.0527\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 8.7326 - mae: 2.0253\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 8.6647 - mae: 2.0348\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 8.6795 - mae: 1.9846\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 8.2998 - mae: 1.9856\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 0s 288us/step - loss: 8.5287 - mae: 1.9911\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 0s 269us/step - loss: 8.4673 - mae: 2.0065\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 8.4491 - mae: 2.0066\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 8.2481 - mae: 2.0004\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 8.2448 - mae: 1.9485\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 7.9359 - mae: 1.9488\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 8.1660 - mae: 1.9632\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 8.0661 - mae: 1.9331\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 7.9593 - mae: 1.9439\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 8.0200 - mae: 1.9140\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 7.9408 - mae: 1.9037\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 0s 269us/step - loss: 7.7784 - mae: 1.9029\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 0s 273us/step - loss: 7.8160 - mae: 1.9222\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 240us/step - loss: 7.6177 - mae: 1.9060\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 0s 245us/step - loss: 7.3369 - mae: 1.8645\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 7.7468 - mae: 1.9192\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 0s 276us/step - loss: 7.5344 - mae: 1.9076\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 7.4590 - mae: 1.8862\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 7.4910 - mae: 1.8693\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 7.5087 - mae: 1.9149\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 7.3221 - mae: 1.8627\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 7.5223 - mae: 1.8782\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 0s 290us/step - loss: 7.0941 - mae: 1.8545\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 7.3817 - mae: 1.8817\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 6.9917 - mae: 1.8388\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 0s 292us/step - loss: 7.2029 - mae: 1.8290\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 7.3054 - mae: 1.8440\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 7.0702 - mae: 1.8290\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 7.0831 - mae: 1.8317\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 0s 292us/step - loss: 6.8290 - mae: 1.8108\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 6.9533 - mae: 1.8235\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 6.8793 - mae: 1.8386\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 6.9642 - mae: 1.8399\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 6.8958 - mae: 1.7981\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.7851 - mae: 1.7839\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 0s 250us/step - loss: 6.6531 - mae: 1.8117\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 6.7325 - mae: 1.7540\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.7327 - mae: 1.7747\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.7040 - mae: 1.7844\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 0s 245us/step - loss: 6.5836 - mae: 1.7625\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 6.4207 - mae: 1.8082\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 6.6280 - mae: 1.7785\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 6.5699 - mae: 1.7768\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 0s 256us/step - loss: 6.4266 - mae: 1.7617\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 0s 236us/step - loss: 6.5453 - mae: 1.7336\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 6.2622 - mae: 1.7372\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.4802 - mae: 1.7700\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 6.3444 - mae: 1.7524\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 6.3238 - mae: 1.7717\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 6.3052 - mae: 1.7386\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 0s 249us/step - loss: 6.2667 - mae: 1.7134\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 0s 238us/step - loss: 6.3824 - mae: 1.7362\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 5.9782 - mae: 1.6689\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 6.2051 - mae: 1.6954\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.1631 - mae: 1.7232\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 0s 249us/step - loss: 6.0710 - mae: 1.6974\n",
      "처리중인 폴드는 # 2\n",
      "shape (101, 13) (101,)\n",
      "shape (303, 13) (303,)\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 0s 554us/step - loss: 535.1801 - mae: 21.0672\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 397.9720 - mae: 17.6584\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 230.5318 - mae: 12.7347\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 105.2250 - mae: 7.7280\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 53.5227 - mae: 5.2117\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 35.5172 - mae: 4.2936\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 26.4773 - mae: 3.7092\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 22.9369 - mae: 3.4268\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 20.1798 - mae: 3.1401\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 0s 276us/step - loss: 18.2024 - mae: 3.0238\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 16.2609 - mae: 2.8883\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 15.3654 - mae: 2.7887\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 14.0276 - mae: 2.6660\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 13.0676 - mae: 2.5756\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 12.3595 - mae: 2.5585\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 11.4017 - mae: 2.4480\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 11.3263 - mae: 2.4221\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 10.7500 - mae: 2.3799\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 10.3307 - mae: 2.3319\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 10.2178 - mae: 2.3072\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 9.8160 - mae: 2.2618\n",
      "Epoch 22/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 9.4738 - mae: 2.2132\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 9.2047 - mae: 2.2114\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 9.1230 - mae: 2.1801\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 8.8734 - mae: 2.1298\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 8.7426 - mae: 2.1556\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 8.3585 - mae: 2.1044\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 8.4590 - mae: 2.1011\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 8.5106 - mae: 2.1262\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 8.2948 - mae: 2.0980\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 8.0323 - mae: 2.0623\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 7.8354 - mae: 2.0589\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 7.8922 - mae: 2.0543\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 7.8673 - mae: 2.0448\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 7.8198 - mae: 2.0069\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 7.5735 - mae: 2.0348\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 7.6168 - mae: 2.0001\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 7.5784 - mae: 1.9862\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 0s 273us/step - loss: 7.3762 - mae: 1.9650\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 275us/step - loss: 7.3459 - mae: 1.9832\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 7.2051 - mae: 1.9668\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 7.2555 - mae: 1.9443\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 7.1917 - mae: 1.9736\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 0s 284us/step - loss: 7.0329 - mae: 1.8979\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 7.0659 - mae: 1.9328\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.9414 - mae: 1.9052\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 6.9257 - mae: 1.8950\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 6.7716 - mae: 1.8816\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 6.8721 - mae: 1.9041\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.7436 - mae: 1.8356\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 0s 263us/step - loss: 6.6485 - mae: 1.8614\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 6.5650 - mae: 1.8514\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 0s 269us/step - loss: 6.5692 - mae: 1.8718\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.5138 - mae: 1.8471\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 6.3460 - mae: 1.8284\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 6.4352 - mae: 1.8104\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 6.2304 - mae: 1.8045\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.3167 - mae: 1.7908\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.2276 - mae: 1.8187\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 6.1153 - mae: 1.7982\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 6.1593 - mae: 1.7882\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 6.1296 - mae: 1.7858\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.1614 - mae: 1.7654\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 0s 285us/step - loss: 5.9738 - mae: 1.7374\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 5.8382 - mae: 1.7383\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 5.8170 - mae: 1.7783\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 5.9066 - mae: 1.7834\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 5.8948 - mae: 1.7470\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 5.8471 - mae: 1.7341\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 5.7547 - mae: 1.7432\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 5.7848 - mae: 1.7529\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 5.6728 - mae: 1.7241\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 5.7840 - mae: 1.7173\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 5.6424 - mae: 1.7275\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 5.7629 - mae: 1.6985\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 5.5031 - mae: 1.6845\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 5.4383 - mae: 1.6879\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 5.4718 - mae: 1.6846\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 5.5295 - mae: 1.6880\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 5.4448 - mae: 1.6557\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 5.3139 - mae: 1.6734\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 5.4752 - mae: 1.6654\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 5.1876 - mae: 1.6496\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 5.2509 - mae: 1.6333\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 0s 280us/step - loss: 5.3503 - mae: 1.6494\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 0s 270us/step - loss: 5.1517 - mae: 1.6589\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 5.2971 - mae: 1.6467\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 5.2551 - mae: 1.6506\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 5.1864 - mae: 1.6345\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 5.0161 - mae: 1.6335\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 4.9705 - mae: 1.6032\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 5.1349 - mae: 1.6046\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 0s 264us/step - loss: 4.9629 - mae: 1.5593\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 0s 259us/step - loss: 4.8042 - mae: 1.5814\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 5.0114 - mae: 1.6024\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 4.9376 - mae: 1.5918\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 0s 278us/step - loss: 5.0060 - mae: 1.6106\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 4.6640 - mae: 1.5390\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 4.8228 - mae: 1.5771\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 4.7577 - mae: 1.5817\n",
      "처리중인 폴드는 # 3\n",
      "shape (101, 13) (101,)\n",
      "shape (303, 13) (303,)\n",
      "Epoch 1/100\n",
      "303/303 [==============================] - 0s 548us/step - loss: 461.5188 - mae: 19.6461\n",
      "Epoch 2/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 316.8733 - mae: 15.6916\n",
      "Epoch 3/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 169.9886 - mae: 10.6882\n",
      "Epoch 4/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 70.3082 - mae: 6.2540\n",
      "Epoch 5/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 38.1125 - mae: 4.4724\n",
      "Epoch 6/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 28.9256 - mae: 3.7734\n",
      "Epoch 7/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 23.7762 - mae: 3.4415\n",
      "Epoch 8/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 20.3232 - mae: 3.1241\n",
      "Epoch 9/100\n",
      "303/303 [==============================] - 0s 264us/step - loss: 18.5026 - mae: 3.0373\n",
      "Epoch 10/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 16.8837 - mae: 2.8697\n",
      "Epoch 11/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 15.8663 - mae: 2.7820\n",
      "Epoch 12/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 14.3896 - mae: 2.6657\n",
      "Epoch 13/100\n",
      "303/303 [==============================] - 0s 259us/step - loss: 13.8242 - mae: 2.6124\n",
      "Epoch 14/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 13.0098 - mae: 2.5019\n",
      "Epoch 15/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 12.1288 - mae: 2.3991\n",
      "Epoch 16/100\n",
      "303/303 [==============================] - 0s 279us/step - loss: 11.7516 - mae: 2.4337\n",
      "Epoch 17/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 11.2589 - mae: 2.3609\n",
      "Epoch 18/100\n",
      "303/303 [==============================] - 0s 271us/step - loss: 11.0867 - mae: 2.3206\n",
      "Epoch 19/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 10.6204 - mae: 2.2577\n",
      "Epoch 20/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 10.2647 - mae: 2.2238\n",
      "Epoch 21/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 9.8053 - mae: 2.2303\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303/303 [==============================] - 0s 272us/step - loss: 9.8599 - mae: 2.1860\n",
      "Epoch 23/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 9.6034 - mae: 2.1716\n",
      "Epoch 24/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 9.4363 - mae: 2.1405\n",
      "Epoch 25/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 9.2344 - mae: 2.1125\n",
      "Epoch 26/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 9.0330 - mae: 2.0935\n",
      "Epoch 27/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 8.8303 - mae: 2.0997\n",
      "Epoch 28/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 8.8587 - mae: 2.0596\n",
      "Epoch 29/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 8.7544 - mae: 2.0736\n",
      "Epoch 30/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 8.6144 - mae: 2.0198\n",
      "Epoch 31/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 8.5020 - mae: 2.0527\n",
      "Epoch 32/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 8.3423 - mae: 1.9927\n",
      "Epoch 33/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 8.3199 - mae: 2.0059\n",
      "Epoch 34/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 8.2737 - mae: 2.0362\n",
      "Epoch 35/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 8.1686 - mae: 2.0085\n",
      "Epoch 36/100\n",
      "303/303 [==============================] - 0s 264us/step - loss: 8.0766 - mae: 1.9862\n",
      "Epoch 37/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 7.8752 - mae: 1.9541\n",
      "Epoch 38/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 7.8531 - mae: 1.9644\n",
      "Epoch 39/100\n",
      "303/303 [==============================] - 0s 275us/step - loss: 7.9247 - mae: 1.9969\n",
      "Epoch 40/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 7.7533 - mae: 1.9782\n",
      "Epoch 41/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 7.6099 - mae: 1.9448\n",
      "Epoch 42/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 7.6719 - mae: 1.9597\n",
      "Epoch 43/100\n",
      "303/303 [==============================] - 0s 260us/step - loss: 7.4844 - mae: 1.9068\n",
      "Epoch 44/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 7.4827 - mae: 1.9144\n",
      "Epoch 45/100\n",
      "303/303 [==============================] - 0s 272us/step - loss: 7.4989 - mae: 1.8769\n",
      "Epoch 46/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 7.3351 - mae: 1.9042\n",
      "Epoch 47/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 7.2180 - mae: 1.8946\n",
      "Epoch 48/100\n",
      "303/303 [==============================] - 0s 300us/step - loss: 7.2698 - mae: 1.8677\n",
      "Epoch 49/100\n",
      "303/303 [==============================] - 0s 289us/step - loss: 7.3522 - mae: 1.8741\n",
      "Epoch 50/100\n",
      "303/303 [==============================] - 0s 298us/step - loss: 7.3255 - mae: 1.8670\n",
      "Epoch 51/100\n",
      "303/303 [==============================] - 0s 296us/step - loss: 7.1356 - mae: 1.8494\n",
      "Epoch 52/100\n",
      "303/303 [==============================] - 0s 291us/step - loss: 7.2076 - mae: 1.8902\n",
      "Epoch 53/100\n",
      "303/303 [==============================] - 0s 277us/step - loss: 7.0119 - mae: 1.8562\n",
      "Epoch 54/100\n",
      "303/303 [==============================] - 0s 276us/step - loss: 6.9151 - mae: 1.8033\n",
      "Epoch 55/100\n",
      "303/303 [==============================] - 0s 266us/step - loss: 7.0169 - mae: 1.8397\n",
      "Epoch 56/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.8638 - mae: 1.7993\n",
      "Epoch 57/100\n",
      "303/303 [==============================] - 0s 281us/step - loss: 6.8814 - mae: 1.8161\n",
      "Epoch 58/100\n",
      "303/303 [==============================] - 0s 295us/step - loss: 6.7877 - mae: 1.7888\n",
      "Epoch 59/100\n",
      "303/303 [==============================] - 0s 280us/step - loss: 6.7768 - mae: 1.8196\n",
      "Epoch 60/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 6.8299 - mae: 1.7878\n",
      "Epoch 61/100\n",
      "303/303 [==============================] - 0s 257us/step - loss: 6.7124 - mae: 1.7784\n",
      "Epoch 62/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.6088 - mae: 1.7891\n",
      "Epoch 63/100\n",
      "303/303 [==============================] - 0s 245us/step - loss: 6.5264 - mae: 1.7517\n",
      "Epoch 64/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.6227 - mae: 1.7624\n",
      "Epoch 65/100\n",
      "303/303 [==============================] - 0s 250us/step - loss: 6.5855 - mae: 1.7424\n",
      "Epoch 66/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.4094 - mae: 1.7408\n",
      "Epoch 67/100\n",
      "303/303 [==============================] - 0s 255us/step - loss: 6.5149 - mae: 1.7513\n",
      "Epoch 68/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.4503 - mae: 1.7590\n",
      "Epoch 69/100\n",
      "303/303 [==============================] - 0s 247us/step - loss: 6.4170 - mae: 1.7441\n",
      "Epoch 70/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 6.4207 - mae: 1.7357\n",
      "Epoch 71/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 6.2750 - mae: 1.7612\n",
      "Epoch 72/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 6.3210 - mae: 1.6961\n",
      "Epoch 73/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 6.2744 - mae: 1.7398\n",
      "Epoch 74/100\n",
      "303/303 [==============================] - 0s 258us/step - loss: 6.4198 - mae: 1.7213\n",
      "Epoch 75/100\n",
      "303/303 [==============================] - 0s 267us/step - loss: 6.1631 - mae: 1.6803\n",
      "Epoch 76/100\n",
      "303/303 [==============================] - 0s 274us/step - loss: 6.2745 - mae: 1.6949\n",
      "Epoch 77/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 6.2238 - mae: 1.6755\n",
      "Epoch 78/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 5.9938 - mae: 1.7011\n",
      "Epoch 79/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 6.0275 - mae: 1.6606\n",
      "Epoch 80/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 6.0844 - mae: 1.6915\n",
      "Epoch 81/100\n",
      "303/303 [==============================] - 0s 262us/step - loss: 5.7367 - mae: 1.6555\n",
      "Epoch 82/100\n",
      "303/303 [==============================] - 0s 254us/step - loss: 6.1898 - mae: 1.7174\n",
      "Epoch 83/100\n",
      "303/303 [==============================] - 0s 268us/step - loss: 6.0680 - mae: 1.6955\n",
      "Epoch 84/100\n",
      "303/303 [==============================] - 0s 265us/step - loss: 5.8594 - mae: 1.6652\n",
      "Epoch 85/100\n",
      "303/303 [==============================] - 0s 249us/step - loss: 5.6392 - mae: 1.6382\n",
      "Epoch 86/100\n",
      "303/303 [==============================] - 0s 256us/step - loss: 6.1406 - mae: 1.7219\n",
      "Epoch 87/100\n",
      "303/303 [==============================] - 0s 245us/step - loss: 5.8442 - mae: 1.6458\n",
      "Epoch 88/100\n",
      "303/303 [==============================] - 0s 245us/step - loss: 5.9663 - mae: 1.6752\n",
      "Epoch 89/100\n",
      "303/303 [==============================] - 0s 254us/step - loss: 5.8431 - mae: 1.6488\n",
      "Epoch 90/100\n",
      "303/303 [==============================] - 0s 249us/step - loss: 5.7360 - mae: 1.6314\n",
      "Epoch 91/100\n",
      "303/303 [==============================] - 0s 264us/step - loss: 5.7563 - mae: 1.6517\n",
      "Epoch 92/100\n",
      "303/303 [==============================] - 0s 248us/step - loss: 5.6518 - mae: 1.6175\n",
      "Epoch 93/100\n",
      "303/303 [==============================] - 0s 251us/step - loss: 5.7328 - mae: 1.6223\n",
      "Epoch 94/100\n",
      "303/303 [==============================] - 0s 269us/step - loss: 5.7169 - mae: 1.6070\n",
      "Epoch 95/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 5.6503 - mae: 1.6218\n",
      "Epoch 96/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 5.7802 - mae: 1.6410\n",
      "Epoch 97/100\n",
      "303/303 [==============================] - 0s 254us/step - loss: 5.5937 - mae: 1.6169\n",
      "Epoch 98/100\n",
      "303/303 [==============================] - 0s 254us/step - loss: 5.6413 - mae: 1.6301\n",
      "Epoch 99/100\n",
      "303/303 [==============================] - 0s 252us/step - loss: 5.5507 - mae: 1.5719\n",
      "Epoch 100/100\n",
      "303/303 [==============================] - 0s 261us/step - loss: 5.4821 - mae: 1.5853\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "for i in range(k):\n",
    "    print('처리중인 폴드는 #', i)\n",
    "    \n",
    "    # 검증 데이터 준비: k번째 분할\n",
    "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    print('shape', val_data.shape, val_targets.shape)\n",
    "    \n",
    "    # 훈련 데이터 준비: 다른 분할 전체\n",
    "    partial_train_data = np.concatenate([train_data[:i * num_val_samples], train_data[(i + 1) * num_val_samples:]], axis=0)\n",
    "    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples], train_targets[(i + 1) * num_val_samples:]], axis=0)\n",
    "    print('shape', partial_train_data.shape, partial_train_targets.shape)\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=10, verbose=1)\n",
    "    \n",
    "    #검증 세트로 모델 평가\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9016305208206177, 2.7204136848449707, 2.6964452266693115, 2.485610008239746]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4510248601436615"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_scores : [1.9016305208206177, 2.7204136848449707, 2.6964452266693115, 2.485610008239746]\n",
      "mean all scores : 2.4510248601436615\n"
     ]
    }
   ],
   "source": [
    "print(f'all_scores : {all_scores}')\n",
    "print(f'mean all scores : {np.mean(all_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 153us/step\n"
     ]
    }
   ],
   "source": [
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0258710384368896"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 모델은 k fold cross validation에서 마지막에 훈련된 모델입니다.\n",
    "# 본 실습에서 별도의 test data set을 구성하지 않았기 때문에, vadliation data set을 이용해 house price 를 예측prediction 해보겠습니다.\n",
    "\n",
    "predictedHousePrice = model.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6196311724067916\n"
     ]
    }
   ],
   "source": [
    "# validation set 은 100개의 데이터 셋으로 구성되어 있습니다만 아래와 같이 1대1 비교를 해보겠습니다.\n",
    "# val_data[0] 에 대한 예측값 predictedHousePrice[0]\n",
    "# val_data[0] 에 대한 실제값 val_targets[0]\n",
    "a = int(val_targets.shape[0])\n",
    "err_sum = 0\n",
    "for i in range(1, a):\n",
    "    error = val_targets[i-1:i]-predictedHousePrice[i-1:i]\n",
    "    #print(predictedHousePrice[i-1:i], \"\\n\", val_targets[i-1:i])\n",
    "    err_sum += error[0][0]\n",
    "    #print('차이:', error[0][0])\n",
    "err_avg = err_sum / a\n",
    "print(err_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측값과 타겟값의 차이의 평균이 0.6으로 Good"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
