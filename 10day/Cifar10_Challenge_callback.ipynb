{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar10이미지를 가지고 keras로 학습하고 예측해본다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코랩을 이용할 거면 구글드라이버 마운트해서 해야함\n",
    "\n",
    "```\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "```\n",
    "```\n",
    "cd gdrive/My Drive/Colab Notebooks/models\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_classes = 10\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "50000\n",
      "(10000, 32, 32, 3)\n",
      "10000\n",
      "(50000, 1)\n",
      "50000\n",
      "(10000, 1)\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_train.shape[0])\n",
    "print(x_test.shape)\n",
    "print(x_test.shape[0])\n",
    "print(y_train.shape)\n",
    "print(y_train.shape[0])\n",
    "print(y_test.shape)\n",
    "print(y_test.shape[0])\n",
    "x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categorical_entoropy를 써야하기에 to_categorical 해줘야 함.\n",
    "# sparse_categorical_crossentopy를 쓸 때는 안해줘도 됨. 알아서 해줌\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n"
     ]
    }
   ],
   "source": [
    "print('Using real-time data augmentation.')\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.,  # set range for random shear\n",
    "    zoom_range=0.,  # set range for random zoom\n",
    "    channel_shift_range=0.,  # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,  # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False,  # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0)\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./saved_model/cifar_saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                                            verbose=1, save_best_only=False,\n",
    "                                            mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네트워크를 직접 설계해보자.\n",
    "n_kernels = 32\n",
    "model = Sequential()\n",
    "\n",
    "# input : 32, 32, 3\n",
    "model.add(Conv2D(n_kernels, (3,3), activation='relu', kernel_initializer='he_normal', padding='same', input_shape=(x_train.shape[1:])))\n",
    "model.add(Conv2D(n_kernels*2, (3,3), activation='relu', kernel_initializer='he_normal', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# input : 32, 32, 64\n",
    "model.add(Conv2D(n_kernels*2, (3,3), activation='relu', kernel_initializer='he_normal', padding='valid'))\n",
    "model.add(Conv2D(n_kernels*4, (3, 3), activation='relu', kernel_initializer='he_normal', padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "# input : 8, 8, 128\n",
    "model.add(Conv2D(n_kernels*8, (3,3), activation='relu', kernel_initializer='he_normal', padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# [중요] GlobalAveragePooling2D() Flatten과 달리 앞 단계 output을 펼치는 것이 아니라\n",
    "# 앞 단계 Conv2D 도출될 피쳐맵(여기선 3*3*256)에서 각 피쳐(3*3)의 평균으로 256노드에 순차적으로 넣어줌)\n",
    "# 그런데 lobalAveragePooling2D() 하면 256노드\n",
    "# Flatten하면 3*3*256 노드\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer='glorot_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 429,706\n",
      "Trainable params: 428,810\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer=opt,\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3125/3125 [==============================] - 29s 9ms/step - loss: 1.5580 - acc: 0.4413 - val_loss: 2.9118 - val_acc: 0.2979\n",
      "\n",
      "Epoch 00001: saving model to ./saved_model/cifar_saved-model-01-0.30.hdf5\n",
      "Epoch 2/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.2899 - acc: 0.5432 - val_loss: 2.8104 - val_acc: 0.3502\n",
      "\n",
      "Epoch 00002: saving model to ./saved_model/cifar_saved-model-02-0.35.hdf5\n",
      "Epoch 3/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.1582 - acc: 0.5957 - val_loss: 1.4073 - val_acc: 0.5240\n",
      "\n",
      "Epoch 00003: saving model to ./saved_model/cifar_saved-model-03-0.52.hdf5\n",
      "Epoch 4/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.0807 - acc: 0.6217 - val_loss: 2.6609 - val_acc: 0.3905\n",
      "\n",
      "Epoch 00004: saving model to ./saved_model/cifar_saved-model-04-0.39.hdf5\n",
      "Epoch 5/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 1.0186 - acc: 0.6439 - val_loss: 3.1851 - val_acc: 0.3264\n",
      "\n",
      "Epoch 00005: saving model to ./saved_model/cifar_saved-model-05-0.33.hdf5\n",
      "Epoch 6/25\n",
      "3125/3125 [==============================] - 27s 9ms/step - loss: 0.9663 - acc: 0.6644 - val_loss: 1.8142 - val_acc: 0.4319\n",
      "\n",
      "Epoch 00006: saving model to ./saved_model/cifar_saved-model-06-0.43.hdf5\n",
      "Epoch 7/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.9255 - acc: 0.6756 - val_loss: 2.2841 - val_acc: 0.4012\n",
      "\n",
      "Epoch 00007: saving model to ./saved_model/cifar_saved-model-07-0.40.hdf5\n",
      "Epoch 8/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.8940 - acc: 0.6888 - val_loss: 2.6397 - val_acc: 0.3538\n",
      "\n",
      "Epoch 00008: saving model to ./saved_model/cifar_saved-model-08-0.35.hdf5\n",
      "Epoch 9/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.8593 - acc: 0.7021 - val_loss: 2.0587 - val_acc: 0.4605\n",
      "\n",
      "Epoch 00009: saving model to ./saved_model/cifar_saved-model-09-0.46.hdf5\n",
      "Epoch 10/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.8311 - acc: 0.7141 - val_loss: 1.7081 - val_acc: 0.4853\n",
      "\n",
      "Epoch 00010: saving model to ./saved_model/cifar_saved-model-10-0.49.hdf5\n",
      "Epoch 11/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.8047 - acc: 0.7227 - val_loss: 1.5402 - val_acc: 0.5045\n",
      "\n",
      "Epoch 00011: saving model to ./saved_model/cifar_saved-model-11-0.50.hdf5\n",
      "Epoch 12/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.7864 - acc: 0.7296 - val_loss: 1.4973 - val_acc: 0.5235\n",
      "\n",
      "Epoch 00012: saving model to ./saved_model/cifar_saved-model-12-0.52.hdf5\n",
      "Epoch 13/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.7702 - acc: 0.7356 - val_loss: 5.1686 - val_acc: 0.2812\n",
      "\n",
      "Epoch 00013: saving model to ./saved_model/cifar_saved-model-13-0.28.hdf5\n",
      "Epoch 14/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.7533 - acc: 0.7398 - val_loss: 2.3327 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00014: saving model to ./saved_model/cifar_saved-model-14-0.42.hdf5\n",
      "Epoch 15/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.7383 - acc: 0.7469 - val_loss: 5.3189 - val_acc: 0.2735\n",
      "\n",
      "Epoch 00015: saving model to ./saved_model/cifar_saved-model-15-0.27.hdf5\n",
      "Epoch 16/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.7206 - acc: 0.7513 - val_loss: 3.9309 - val_acc: 0.3897\n",
      "\n",
      "Epoch 00016: saving model to ./saved_model/cifar_saved-model-16-0.39.hdf5\n",
      "Epoch 17/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.7081 - acc: 0.7566 - val_loss: 1.4180 - val_acc: 0.5827\n",
      "\n",
      "Epoch 00017: saving model to ./saved_model/cifar_saved-model-17-0.58.hdf5\n",
      "Epoch 18/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6957 - acc: 0.7594 - val_loss: 2.9148 - val_acc: 0.3858\n",
      "\n",
      "Epoch 00018: saving model to ./saved_model/cifar_saved-model-18-0.39.hdf5\n",
      "Epoch 19/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6776 - acc: 0.7690 - val_loss: 3.4112 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00019: saving model to ./saved_model/cifar_saved-model-19-0.36.hdf5\n",
      "Epoch 20/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6624 - acc: 0.7739 - val_loss: 7.7645 - val_acc: 0.2193\n",
      "\n",
      "Epoch 00020: saving model to ./saved_model/cifar_saved-model-20-0.22.hdf5\n",
      "Epoch 21/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6610 - acc: 0.7734 - val_loss: 2.0358 - val_acc: 0.5005\n",
      "\n",
      "Epoch 00021: saving model to ./saved_model/cifar_saved-model-21-0.50.hdf5\n",
      "Epoch 22/25\n",
      "3125/3125 [==============================] - 27s 9ms/step - loss: 0.6493 - acc: 0.7780 - val_loss: 1.1979 - val_acc: 0.6175\n",
      "\n",
      "Epoch 00022: saving model to ./saved_model/cifar_saved-model-22-0.62.hdf5\n",
      "Epoch 23/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6410 - acc: 0.7791 - val_loss: 1.2390 - val_acc: 0.6101\n",
      "\n",
      "Epoch 00023: saving model to ./saved_model/cifar_saved-model-23-0.61.hdf5\n",
      "Epoch 24/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6307 - acc: 0.7849 - val_loss: 2.4704 - val_acc: 0.4328\n",
      "\n",
      "Epoch 00024: saving model to ./saved_model/cifar_saved-model-24-0.43.hdf5\n",
      "Epoch 25/25\n",
      "3125/3125 [==============================] - 28s 9ms/step - loss: 0.6231 - acc: 0.7874 - val_loss: 2.2900 - val_acc: 0.4789\n",
      "\n",
      "Epoch 00025: saving model to ./saved_model/cifar_saved-model-25-0.48.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2cbfa355b00>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                   epochs=epochs, validation_data=(x_test, y_test),\n",
    "                   workers=4, callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
